\section{Evaluation}

\subsection{First Evaluation}

The first evaluation in the second phase of the project occurred in November 2014.  The user group was made up of two people.  One who had taken part in the first evaluation meeting and one person who had no knowledge of the project.

\subsubsection{User Group}

As I did not have a domain expert available I was not able to do insight based evaluation.  I took a more traditional approach.  Before the evaluation I prepared a typical scenario that a user might encounter.  The task was to open a file, annotate it and run the animation visualisation, and attach supporting documentation.  The task was prepared at two levels of instruction.  The first level was a paragraph of text that described what was to be done.  The second level was a step by step list of instructions to perform.  I observed the user group as they attempted the task and offered assistance when required.  Afterwards the user group was given a questionnaire to fill in about their experience, afterwords we went through and discussed their answers and any further thoughts that they had.

The task was prepared at two levels to try and gauge how easy the program is too use.  The users were first presented with the textual description and if they had been unable to complete the task with this then they would have been given the step by step instructions instead.  The users were able to complete the task from the textual description alone.  This is a good sign that the new tool is usable.

Some issues were encountered:

\begin{itemize}
\item User's were unfamiliar with MacOS -- Both users were unable to locate the menu bar as it is not attached to the program as in Windows.  Future evaluations will use Windows.
\item When annotating they were unclear as to what was going to happen when annotating.  For example when annotating the graph with an arrow the user has to click twice to place but there is no indication of this, nor was it clear to them which way the arrow would be drawn.  This has now been fixed. Different cursors are used to give feedback to the user that they should click, and rather than just relying on two clicks with no information as to where the arrow is going to point, after the first click (which places the tail of the arrow) an arrow will be drawn that follows the cursor until the second click placing the annotation.
\item Lack of ability to edit, move, or delete annotations -- Once an annotation was placed it was there permanently.  The ability to edit annotations was always planned, but had not been implemented in time.  But the amount of frustration it gave the users was very high.  It was a principle in all three of Norman, Neilson and Schniederman's lists that a user should be able to fix mistakes.  Since the evaluation editing and deleting of annotations have been implemented.  This means any mistakes can be corrected.
\item Initially they were confused by what all the buttons on the matplotlib toolbar did.  After discovering the tooltips and seeing what effect the buttons had they were comfortable with them.  If a user were to do something they did not intend they are able to undo it. All the matplotlib built in buttons on the toolbar can be undone and redone from the toolbar.  Any buttons implemented for this tool are covered by the undo and redo functionality implemented across the whole program.  Being able to recover from their actions on the toolbar means no hindrance to discovery and so needs no further action.  It would be desirable to have the two undo methods unified but a way to do this could not be found.
\item The users were confused by some of the terminology.  In particular ``save graph'' and ``save model''.  They were confused between the two. These items in the menu have now been grouped more carefully to help the user distinguish them.  A related issue was worrying that ``save graph'' was going to override the results file.  To rectify this the menu items that create new files have been renamed ``export ...''.
\item The users struggled to start a new session.  When asked for a title they did not know what the title was going to be used for.  When trying to add files, rather than use the add files button in the dialogue, they tried to use the file menu.  Having two routes into doing the visualisation seemed to be confusing them.  Now the file menu open file has been removed.  To create a visualisation the user has to go through the new session wizard.
\item When placing species in the cell one of the users did not understand what they were being asked to do.  One of the users did understand.  To fix this user input has been removed from the equation.  This has required the model file to also be chosen, but then species locations are parsed automatically.
\item They liked the animation feature and thought it would be very useful (One of the users did their PhD in transport and expressed a desire to have had this feature during the PhD).  They did feel that it wouldn't be useful directly for papers, but that it would be useful when deciding what to include in a paper.
\item One of the users asked if they was a map of the cell.  When presented with the model visualisation they thought that it did look nice, but were unsure of its usefulness.  The model viewing has since been merged into the animation visualisation.
\item The results from the questionnaire indicated that both users thought the tool's appearance was good.  The tool was average in difficulty to use -- neither easy nor difficult. The annotation buttons on the toolbar were clear as to what they did. It was obvious how to attach supporting files.  Both users thought that it is very useful to attach files to the session so that they can be easily emailed to a colleague.  They thought it would be useful to have the graph automatically annotated, but they wanted to the ability to disable turn off any automatic annotations.  Both users found the animation useful.
\end{itemize}

\subsubsection{Personal}

At this stage in the development the program was in a state where some existing functionality had been broken and gone unnoticed during the implementation of the new features.  This highlighted architectural flaws in the code.  There were multiple paths through the program that data was taking, and duplicated code in places.  Since then a majority of these bugs have been ironed out and the duplications removed. The code much better architected.  At the time of the evaluation with the users not all the features could be tested with them -- mainly the plot preferences dialogue.  These features have now been fixed and they will be evaluated by the users at the next meeting.

Having the users use the program has also highlighted a number of usability problems: menus being badly organised and named, features such as annotation rely on assumed knowledge to work them.  All this created a unfriendly environment for the user.  This was due to losing sight of the need for usability during development and when testing new features not removing the knowledge of the code from my mind.  Since this evaluation the three lists of usability have been refocused on and the code gone through and the principles applied

I am pleased with the positive feedback on animation and annotation -- two of the core new features.

\subsection{Evaluation 2 - Start of Second Semester}
\subsubsection{User Group}
\subsubsection{Personal}

\subsection{Evaluation 3 - End of Second Semester}
\subsubsection{User Group}
\subsubsection{Expert User}
\subsubsection{Personal}

\subsection{Overrall Self Evaluation}
Scribble over lots of stuff talk about changes
